openapi: 3.0.0
info:
  title: BRMH LLM SERVICE
  version: 1.0.0
  description: LLM-powered schema generation for BRMH

paths:
  /llm/generate-schema:
    post:
      summary: Generate schema or code from prompt using LLM
      description: |
        The LLM will return ONLY code (for code prompts) or ONLY valid JSON/YAML (for schema/config prompts), with no explanations or markdown. The response is always the raw code or object.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                prompt:
                  type: string
                  example: "Generate a JSON schema for a project management app with users, projects, tasks, and comments."
      responses:
        '200':
          description: Generated schema
          content:
            application/json:
              schema:
                type: object
                properties:
                  schema:
                    type: object
                  llm_output:
                    type: string
        '400':
          description: Invalid request
          content:
            application/json:
              schema:
                type: object
                properties:
                  error:
                    type: string
  /llm/generate-schema/stream:
    post:
      summary: Generate schema or code from prompt using LLM (streaming)
      description: |
        The LLM will return ONLY code (for code prompts) or ONLY valid JSON/YAML (for schema/config prompts), with no explanations or markdown. The response is always the raw code or object.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                prompt:
                  type: string
                  example: "Generate a JSON schema for a project management app with users, projects, tasks, and comments."
      responses:
        '200':
          description: Streamed generated schema
          content:
            text/event-stream:
              schema:
                type: string
        '400':
          description: Invalid request
          content:
            application/json:
              schema:
                type: object
                properties:
                  error:
                    type: string 
  /llm/templates:
    get:
      summary: List all prompt templates
      responses:
        '200':
          description: List of templates
          content:
            application/json:
              schema:
                type: array
                items:
                  type: object
                  properties:
                    id: { type: string }
                    name: { type: string }
                    context: { type: string }
                    message: { type: string }
    post:
      summary: Save a new prompt template
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                name: { type: string }
                context: { type: string }
                message: { type: string }
      responses:
        '201':
          description: Template saved

  /llm/history:
    get:
      summary: List LLM output history
      responses:
        '200':
          description: List of history items
          content:
            application/json:
              schema:
                type: array
                items:
                  type: object
                  properties:
                    id: { type: string }
                    prompt: { type: string }
                    output: { type: string }
                    timestamp: { type: string }
    post:
      summary: Save LLM output history
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                prompt: { type: string }
                output: { type: string }
      responses:
        '201':
          description: History saved

  /generate-schema/stream:
    post:
      operationId: generateSchemaWithLLMStream
      summary: Generate schema with streaming response
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required: ["prompt"]
              properties:
                prompt:
                  type: string
                  description: The prompt to generate schema from
      responses:
        '200':
          description: Schema generation stream
          content:
            text/event-stream:
              schema:
                type: string
                description: Server-sent events stream
        '400':
          description: Bad request
          content:
            application/json:
              schema:
                type: object
                properties:
                  error:
                    type: string
        '500':
          description: Server error
          content:
            application/json:
              schema:
                type: object
                properties:
                  error:
                    type: string

  /generate-schema:
    post:
      operationId: generateSchemaWithLLM
      summary: Generate schema
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required: ["prompt"]
              properties:
                prompt:
                  type: string
                  description: The prompt to generate schema from
      responses:
        '200':
          description: Schema generated successfully
          content:
            application/json:
              schema:
                type: object
                properties:
                  schema:
                    type: object
                  isArray:
                    type: boolean
                  originalType:
                    type: string

  /llm/count-tokens:
    post:
      summary: Count tokens in a text
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                text:
                  type: string
      responses:
        '200':
          description: Token count
          content:
            application/json:
              schema:
                type: object
                properties:
                  tokenCount:
                    type: integer
        '400':
          description: Invalid request
          content:
            application/json:
              schema:
                type: object
                properties:
                  error:
                    type: string 